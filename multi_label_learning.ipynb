{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a0483d-eea9-4cab-9d69-362a24220402",
   "metadata": {},
   "source": [
    "# Multi-Label-Learning for DeliciousMIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6f700-2bb5-422a-9063-8178fd37adaa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0524526-98bf-4a33-8edf-d2cd1c43e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import zero_one_loss, coverage_error, label_ranking_loss, label_ranking_average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c60463-6be3-4b61-a209-f656a4c19315",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f489fdf-1a47-47e7-8efd-701efc230138",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = os.getcwd()\n",
    "dataset_dir = my_path + '/DeliciousMIL/Data/'\n",
    "dataset_dir = dataset_dir.replace('\\\\', '/')\n",
    "\n",
    "input_train_data = dataset_dir + 'train-data.dat'\n",
    "output_train_data = dataset_dir + 'train-data.txt'\n",
    "output_train_data2 = dataset_dir + 'train-data2.txt'\n",
    "input_test_data = dataset_dir + 'test-data.dat'\n",
    "output_test_data = dataset_dir + 'test-data.txt'\n",
    "output_test_data2 = dataset_dir + 'test-data2.txt'\n",
    "\n",
    "input_train_label = dataset_dir + 'train-label.dat'\n",
    "output_train_label = dataset_dir + 'train-label.txt'\n",
    "output_train_label2 = dataset_dir + 'train-label2.txt'\n",
    "input_test_label = dataset_dir + 'test-label.dat'\n",
    "output_test_label = dataset_dir + 'test-label.txt'\n",
    "output_test_label2 = dataset_dir + 'test-label2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c7769c-a593-4963-9fc3-63a547d59424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    pattern = r'<[^>]+>'\n",
    "    content = re.sub(pattern, '', content)\n",
    "\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "\n",
    "def replace_multiple_spaces(input_file, output_file):\n",
    "    with open(output_file, 'w') as file2:\n",
    "        with open(input_file, 'r') as file:\n",
    "            for line in file:\n",
    "                content = line\n",
    "                content = ' '.join(content.split())\n",
    "\n",
    "                file2.write(content)\n",
    "                file2.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a479b649-4b9b-4171-ad14-bd56f96f56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_X_train = []\n",
    "with open(output_train_data2, 'r') as file:\n",
    "    for line in file:\n",
    "        pattern = r'\\n'\n",
    "        line = re.sub(pattern, '', line)\n",
    "        corpus_X_train.append(line)\n",
    "        \n",
    "corpus_X_test = []\n",
    "with open(output_test_data2, 'r') as file:\n",
    "    for line in file:\n",
    "        pattern = r'\\n'\n",
    "        line = re.sub(pattern, '', line)\n",
    "        corpus_X_test.append(line)\n",
    "        \n",
    "corpus_y_train = []\n",
    "with open(output_train_label2, 'r') as file:\n",
    "    for line in file:\n",
    "        pattern = r'\\n'\n",
    "        line = re.sub(pattern, '', line)\n",
    "        content = line.split(\" \")\n",
    "\n",
    "        for i in range(0, len(content)):\n",
    "            content[i] = int(content[i])\n",
    "\n",
    "        content = np.array(content)\n",
    "\n",
    "        corpus_y_train.append(content)\n",
    "\n",
    "corpus_y_test = []\n",
    "with open(output_test_label2, 'r') as file:\n",
    "    for line in file:\n",
    "        pattern = r'\\n'\n",
    "        line = re.sub(pattern, '', line)\n",
    "        content = line.split(\" \")\n",
    "\n",
    "        for i in range(0, len(content)):\n",
    "            content[i] = int(content[i])\n",
    "\n",
    "        corpus_y_test.append(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565183c-fac7-4d32-b7c7-d2325d0fe31d",
   "metadata": {},
   "source": [
    "TfidfVectorizer is used for the vectorization of training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3a12a2-aaec-429a-b612-9c7b9eaee157",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(corpus_X_train)\n",
    "X_test = vectorizer.transform(corpus_X_test)\n",
    "y_train = np.array(corpus_y_train)\n",
    "y_test = np.array(corpus_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63673c-a5a5-4547-b3aa-54fd85680a8c",
   "metadata": {},
   "source": [
    "## Comparison between the following multi-label models:\n",
    "<ou>\n",
    "    <li>Classifier Chain (Logistic Regression)</li>\n",
    "    <li>Ensemble Method (Random Forest Classifier)</li>\n",
    "</ou>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af719459-8352-48bf-83bb-fb2127e10869",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['CC', 'RF']\n",
    "classifiers = [ClassifierChain(LogisticRegression(random_state=0)),\n",
    "               RandomForestClassifier(n_estimators=200),\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18299a6-5d73-4725-9497-1caa2e4f3af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC\n",
      "MSE: 0.12\n",
      "MAE: 0.12\n",
      " R2: -0.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.58      0.69       977\n",
      "           1       0.94      0.14      0.24       228\n",
      "           2       0.67      0.39      0.49      1558\n",
      "           3       0.81      0.47      0.60       372\n",
      "           4       0.71      0.37      0.48      1050\n",
      "           5       0.48      0.14      0.22       537\n",
      "           6       0.61      0.12      0.20       702\n",
      "           7       0.76      0.26      0.39      1079\n",
      "           8       0.71      0.30      0.42       803\n",
      "           9       0.78      0.27      0.40       483\n",
      "          10       0.73      0.21      0.33       507\n",
      "          11       0.86      0.13      0.23       478\n",
      "          12       0.61      0.09      0.15       509\n",
      "          13       0.70      0.17      0.27       355\n",
      "          14       0.76      0.24      0.36       392\n",
      "          15       0.72      0.06      0.12       441\n",
      "          16       0.66      0.09      0.16       269\n",
      "          17       0.87      0.16      0.26       501\n",
      "          18       0.86      0.15      0.26       207\n",
      "          19       0.70      0.17      0.28       133\n",
      "\n",
      "   micro avg       0.73      0.27      0.40     11581\n",
      "   macro avg       0.74      0.23      0.33     11581\n",
      "weighted avg       0.73      0.27      0.38     11581\n",
      " samples avg       0.39      0.26      0.29     11581\n",
      "\n",
      "subset accuracy   : 0.10\n",
      "coverage error    : 7.26\n",
      "ranking loss      : 0.14\n",
      "average precision : 0.69\n",
      "RF\n",
      "MSE: 0.13\n",
      "MAE: 0.13\n",
      " R2: -0.11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.40      0.54       977\n",
      "           1       0.94      0.07      0.12       228\n",
      "           2       0.80      0.10      0.18      1558\n",
      "           3       0.97      0.17      0.28       372\n",
      "           4       0.88      0.14      0.24      1050\n",
      "           5       0.64      0.01      0.03       537\n",
      "           6       0.68      0.02      0.04       702\n",
      "           7       0.76      0.09      0.16      1079\n",
      "           8       0.81      0.05      0.10       803\n",
      "           9       0.90      0.07      0.14       483\n",
      "          10       0.83      0.06      0.11       507\n",
      "          11       0.68      0.03      0.05       478\n",
      "          12       0.44      0.01      0.02       509\n",
      "          13       0.89      0.07      0.13       355\n",
      "          14       0.95      0.05      0.10       392\n",
      "          15       0.42      0.01      0.02       441\n",
      "          16       0.57      0.01      0.03       269\n",
      "          17       0.88      0.03      0.06       501\n",
      "          18       0.91      0.05      0.09       207\n",
      "          19       0.67      0.03      0.06       133\n",
      "\n",
      "   micro avg       0.84      0.09      0.17     11581\n",
      "   macro avg       0.77      0.07      0.12     11581\n",
      "weighted avg       0.78      0.09      0.16     11581\n",
      " samples avg       0.18      0.09      0.11     11581\n",
      "\n",
      "subset accuracy   : 0.07\n",
      "coverage error    : 7.60\n",
      "ranking loss      : 0.16\n",
      "average precision : 0.65\n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "  print(name)\n",
    "  clf.fit(X_train, y_train)\n",
    "  y_pred = clf.predict(X_test)\n",
    "\n",
    "  print('MSE: %.2f' % (mean_squared_error(y_test, y_pred)))\n",
    "  print('MAE: %.2f' % (mean_absolute_error(y_test, y_pred)))\n",
    "  print(' R2: %.2f' % (r2_score(y_test, y_pred)))\n",
    "\n",
    "  print(classification_report(y_test,y_pred,zero_division='warn'))\n",
    "  print('subset accuracy   : %.2f' % (1-zero_one_loss(y_test, y_pred)))\n",
    "\n",
    "  if name == 'CC' or name == 'MLP':\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "  else:\n",
    "    y_proba = np.array([[k[1] for k in i] for i in clf.predict_proba(X_test)]).T\n",
    " \n",
    "  print('coverage error    : %.2f' % (coverage_error(y_test, y_proba)))\n",
    "  print('ranking loss      : %.2f' % (label_ranking_loss(y_test, y_proba)))\n",
    "  print('average precision : %.2f' % (label_ranking_average_precision_score(y_test, y_proba)))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c759958-68a1-431b-9446-4fabb88a40c9",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Reviewing the results above, it's clear that the Logistic Regression model shows slightly superior performance in terms of MSE, MAE, and R2. Additionally, the model outperforms in subset accuracy, coverage error, ranking loss, and average precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
